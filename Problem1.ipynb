{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeremy Kazimer\n",
    "#### 5018-1732\n",
    "#### Assignment #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, the import statements should be at the top of the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, we can recreate the previous assignment, that is to say the wave function, but this time by solving it via TensorFlow.  The equations are still the same, but now we must adjust all of our inputs such that they follow the TensorFlow formula.  Namely,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kernel(a):\n",
    "    \n",
    "    \"\"\"Transform a 2D array into a convolution kernel\"\"\"\n",
    "    \n",
    "    a = np.asarray(a)\n",
    "    a = a.reshape(list(a.shape) + [1,1])\n",
    "    \n",
    "    return tf.constant(a, dtype=1)\n",
    "\n",
    "def simple_conv(x, k):\n",
    "    \n",
    "    \"\"\"A simplified 2D convolution operation\"\"\"\n",
    "    \n",
    "    x = tf.expand_dims(tf.expand_dims(x, 0), -1)\n",
    "    y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    return y[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where this code comes from the CompPhys repository [here](https://github.com/ubsuny/CompPhys/blob/PDEupdate/PDEs/CNN-PDE.ipynb).  All code from this point on will as well, unless otherwise specified.  We can then apply this to the Laplace and its isotropic equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_iso(x):\n",
    "    \n",
    "    \"\"\"Compute the 2D Laplacian of an array\"\"\"\n",
    "    \n",
    "    laplace_k = make_kernel([[0.25, 0.5, 0.25],\n",
    "                           [0.5, -3., 0.5],\n",
    "                           [0.25, 0.5, 0.25]])\n",
    "    \n",
    "    return simple_conv(x, laplace_k)\n",
    "\n",
    "def laplace(x):\n",
    "    \n",
    "    \"\"\"Compute the 2D Laplacian of an array\"\"\"\n",
    "    \n",
    "    laplace_k = make_kernel([[0., 1., 0.],\n",
    "                           [1., -4., 1.],\n",
    "                           [0., 1., 0.]])\n",
    "    \n",
    "    return simple_conv(x, laplace_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $L$ is fixed here, which is fine.  Since the purpose of this experiment is to more-so observe runtimes, we don't have to vary it.  Now, with the base functions implemented, we can look to the actual TensorFlow implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager execution normally means that things are calculated as they come up...this is great for TensorFlow 2.0 and onwards, but not so much 1.14, which is what the Pi Zero W runs on.  As such, we disable it so that it doesn't interfere.  We must also declare our initial conditions from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "u_init = np.zeros([N, N], dtype = np.float32)\n",
    "ut_init = np.zeros([N, N], dtype = np.float32)\n",
    "\n",
    "u_init[N//2, N//2] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create TensorFlow variables! These act very similarly to SymPy, but with far more shorthand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    eps -> a constant.  In perturbation theory, this is the perturbation parameter.  It applies here as well,\n",
    "    since it determines how much the original equation is offset by the delta.\n",
    "    \n",
    "    damping -> a constant, representing the system damping.  This prevents the system from growing much faster.\n",
    "    \n",
    "    c -> This is the speed of light, but for a toy model it's rather arbitrary.\n",
    "'''\n",
    "\n",
    "eps = tf.placeholder(tf.float32, shape=())\n",
    "damping = tf.placeholder(tf.float32, shape=())\n",
    "c = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "U  = tf.Variable(u_init)\n",
    "Ut = tf.Variable(ut_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our equivalent functions, from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ = U + eps * Ut\n",
    "Ut_ = Ut + eps * ((c ** 2) * laplace(U) - damping * Ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = tf.group(\n",
    "    U.assign(U_),\n",
    "    Ut.assign(Ut_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `tf.group()` functions forces both values `U` and `Ut` to be updated at the same time.  We can now run this for $1000$ steps, and time each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 1000\n",
    "ts = np.zeros((nsteps))\n",
    "\n",
    "for n in range(nsteps):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    step.run({eps: 0.03, damping: 0.04, c: 3.0})\n",
    "    \n",
    "    t1 = time.time()\n",
    "    ts[n] = t1 - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (12, 4))\n",
    "\n",
    "ax.hist(ts, 10, color = 'navy')\n",
    "\n",
    "ax.set_ylabel('counts', fontsize = 14)\n",
    "ax.set_xlabel('computation time, $t$', fontsize = 14)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_avg = np.average(ts)\n",
    "t_err = np.std(ts)/np.sqrt(nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average runtime per iteration: 0.02038 pm 0.00014 seconds\n"
     ]
    }
   ],
   "source": [
    "print('average runtime per iteration: {:.5f} pm {:.5f} seconds'.format(t_avg, t_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really, besides the actual variable updating, the main computational contribution comes from re-calculating the convolution at each step since matrix multiplication is not an inexpensive process.  I know that NumPy has it down to nearly $\\mathcal{O}(N^3)$, but that's still horrendous.  It is that `nn.depthwise_conv2d()` function that is taking all of the time.  \n",
    "\n",
    "Otherwise, the original Notebook had a lot of display utilities.  Creating a graph is not an expensive process, and one that updates no less:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (12, 4))\n",
    "\n",
    "ax.hist(ts, 10, color = 'navy')\n",
    "\n",
    "ax.set_ylabel('counts', fontsize = 14)\n",
    "ax.set_xlabel('computation time, $t$', fontsize = 14)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without expending the Pi's resources, we can just look at one case and see that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting time: 0.08078 seconds\n"
     ]
    }
   ],
   "source": [
    "print('plotting time: {:.5f} seconds'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 4 times as long as doing the actual computation per iteration...interesting.  Of course, more practically you would plot the end behavior, so you wouldn't be making, well, 1000 plots.  But for demonstrative purposes, that is a lot of graphs being made.  Since the runtime for each should be practically the same since no conditions are changing, this would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting time: 80.77502 seconds\n"
     ]
    }
   ],
   "source": [
    "print('plotting time: {:.5f} seconds'.format(nsteps*(t1 - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, by removing the active display I actually saved myself a bit of time! Perhaps doing `expand_dims()` twice will contribute to the runtime significantly as well, since this is expanding a two dimensional array, twice.  Note that extending a 2D array at its worse time case will be $\\mathcal{O}(N^2)$, as [defined here](https://www.geeksforgeeks.org/append-extend-python/) for a 1-D array, which is still not as worse as the matrix multiplication.  Either way, the Pi Zero W is still terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
